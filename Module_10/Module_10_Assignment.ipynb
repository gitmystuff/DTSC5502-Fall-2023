{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC5502/blob/main/Module_10/Module_10_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfa4ccd",
      "metadata": {
        "id": "5cfa4ccd"
      },
      "source": [
        "# Module 10 Assignment\n",
        "\n",
        "by Your Name\n",
        "\n",
        "## Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be sure to replace the stud_id variable with you student id. Automatic 0 if not properly replaced."
      ],
      "metadata": {
        "id": "T_NyOA_WUhEC"
      },
      "id": "T_NyOA_WUhEC"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0d58ad25",
      "metadata": {
        "id": "0d58ad25"
      },
      "outputs": [],
      "source": [
        "# create seed, run this cell as is, only edit your stud_id\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "n = 500\n",
        "\n",
        "def make_null(r, w):\n",
        "    # rtn = random.choices([np.nan, r])\n",
        "    wi = w * .1\n",
        "    rtn = np.random.choice([r, np.NaN], p=[1-wi, wi])\n",
        "    return re.sub(r\"[\\[\\]]\",'', str(rtn))\n",
        "\n",
        "\n",
        "# provide your student id as stud_id, replace 123456789 (automatice 0 if not replaced with your student id)\n",
        "stud_id = 123456789\n",
        "my_seed = random.seed(stud_id)\n",
        "\n",
        "# Do not edit this cell beyond this line\n",
        "variables = [''.join(random.choices(string.ascii_lowercase, k=5)) for _ in range(50)]\n",
        "print(variables)\n",
        "cols = variables[:20]\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=500,\n",
        "    n_features=20,\n",
        "    n_informative=5,\n",
        "    n_classes=2,\n",
        "    flip_y=0.4,\n",
        "    class_sep=0.1,\n",
        "    n_redundant=5,\n",
        "    n_repeated=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(data=X, columns=cols)\n",
        "# df[cols[0]] = round(df[cols[0]], 4)\n",
        "# df[variables[20]] = 0.03\n",
        "# df[variables[21]] = 0.07\n",
        "# df[variables[22]] = df[variables[0]]\n",
        "# df[variables[23]] = df[cols[1]]\n",
        "# df[variables[24]] = df[variables[20]].apply(make_null, args=(1,))\n",
        "# df[variables[25]] = df[variables[13]].apply(make_null, args=(1,))\n",
        "\n",
        "df[variables[21]] = df[cols[1]].apply(lambda r: abs(r) if (r < -0.03) else r)\n",
        "df[variables[22]] = df[cols[2]].apply(lambda r: abs(r)*-1 if (r > 0.02) else r)\n",
        "df[variables[23]] = df[cols[3]].apply(lambda r: abs(r) if (r < -0.01) else r)\n",
        "df[variables[21]] = df[cols[1]].apply(make_null, args=(1,))\n",
        "df[variables[22]] = df[cols[2]].apply(make_null, args=(1,))\n",
        "df[variables[23]] = df[cols[3]].apply(make_null, args=(1,))\n",
        "df[variables[24]] = df[cols[4]].apply(make_null, args=(1,))\n",
        "df[variables[25]] = df[cols[5]].apply(make_null, args=(1,))\n",
        "df[variables[26]] = random.sample(range(100, 1000), k=n)\n",
        "df[variables[27]] = random.sample(range(1000, 10000), k=n)\n",
        "df[variables[28]] = .4\n",
        "df[variables[29]] = .5\n",
        "df[variables[30]] = .6\n",
        "df.loc[97:100, variables[28]] = .6\n",
        "df.loc[98:100, variables[29]] = .5\n",
        "df.loc[99:100, variables[30]] = .4\n",
        "# df[variables[28]] = np.random.choice([.4, .1], p=[.97, .03])\n",
        "# df[variables[29]] = np.random.choice([.5, .2], p=[.98, .02])\n",
        "# df[variables[30]] = np.random.choice([.6, .3], p=[.99, .01])\n",
        "# df[variables[29]] = df[variables[29]].apply(make_null, args=(1,))\n",
        "# df[variables[30]] = df[variables[30]].apply(make_null, args=(1,))\n",
        "# df[variables[31]] = df[variables[31]].apply(make_null, args=(1,))\n",
        "df = df.assign(living=[random.choice(['x', 'o']) for i in range(n)])\n",
        "df = df.assign(treatment=[random.choice(['yes', 'no']) for i in range(n)])\n",
        "df = df.assign(level=[random.choice(['level 1', 'level 2', 'level 3']) for i in range(n)])\n",
        "df = df.assign(magnitude=[random.choice(['magnitude 5', 'magnitude 4', 'magnitude 3', 'magnitude 2', 'magnitude 1']) for i in range(n)])\n",
        "df = df.assign(stage=[random.choice(['stage 10', 'stage 9', 'stage 8', 'stage 7', 'stage 6', 'stage 5', 'stage 4', 'stage 3', 'stage 2', 'stage 1']) for i in range(n)])\n",
        "df['magnitude'] = df['magnitude'].apply(make_null, args=(1,))\n",
        "df['stage'] = df['stage'].apply(make_null, args=(1,))\n",
        "\n",
        "df = df[np.random.default_rng(seed=my_seed).permutation(df.columns.values)]\n",
        "df['class'] = y\n",
        "dupes = df.loc[0:10]\n",
        "df = pd.concat([df, dupes], axis=0)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "df.to_csv('Assignment 10.csv', index=False) # comment this out after successful run so that you don't overwrite your data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the Data"
      ],
      "metadata": {
        "id": "-WzOSay0VOmM"
      },
      "id": "-WzOSay0VOmM"
    },
    {
      "cell_type": "code",
      "source": [
        "# read the dataset created above into a dataframe and output shape, info, and head\n"
      ],
      "metadata": {
        "id": "95TydT6It1YS"
      },
      "id": "95TydT6It1YS",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Prep"
      ],
      "metadata": {
        "id": "L4uBKjebVT79"
      },
      "id": "L4uBKjebVT79"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a8bdc28",
      "metadata": {
        "id": "5a8bdc28"
      },
      "outputs": [],
      "source": [
        "# output and drop constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c1f6efe4",
      "metadata": {
        "id": "c1f6efe4"
      },
      "outputs": [],
      "source": [
        "# output quasi constants and drop quasi constants (don't drop bi-label features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f65de913",
      "metadata": {
        "id": "f65de913"
      },
      "outputs": [],
      "source": [
        "# output and drop duplicate rows, print shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f0276f85",
      "metadata": {
        "id": "f0276f85"
      },
      "outputs": [],
      "source": [
        "# check of duplicate columns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicate features and output shape\n"
      ],
      "metadata": {
        "id": "3nuDA3WyL2b1"
      },
      "id": "3nuDA3WyL2b1",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1c2b124f",
      "metadata": {
        "id": "1c2b124f"
      },
      "source": [
        "### Imputation\n",
        "\n",
        "Use histograms to view the shape of your numerical features.\n",
        "* Use median to replace missing data for skewed features\n",
        "* Use mean to replace missing data for features that look normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ad3159bc",
      "metadata": {
        "id": "ad3159bc"
      },
      "outputs": [],
      "source": [
        "# plot histograms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show null values for each variable\n"
      ],
      "metadata": {
        "id": "nbAh7UBkHSvc"
      },
      "id": "nbAh7UBkHSvc",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print info to recall which variables are numeric vs categorical\n"
      ],
      "metadata": {
        "id": "PoJs2L-0MHQt"
      },
      "id": "PoJs2L-0MHQt",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a5b1afe7",
      "metadata": {
        "id": "a5b1afe7"
      },
      "outputs": [],
      "source": [
        "# replace missing data with appropriate mean, median, or mode and confirm with isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "e8HY-whQxJ7n"
      },
      "id": "e8HY-whQxJ7n"
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split (class is the binary dependent (y) variable), print the shapes for X_train and X_test\n"
      ],
      "metadata": {
        "id": "hRgrnMZFxb6K"
      },
      "id": "hRgrnMZFxb6K",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important:** We will not be using df (the dataframe we created above) for the remaining code. Instead we will be using X_train for df and X_test when appropriate."
      ],
      "metadata": {
        "id": "vdjLRyFbH_Cp"
      },
      "id": "vdjLRyFbH_Cp"
    },
    {
      "cell_type": "markdown",
      "id": "5ccc846c",
      "metadata": {
        "id": "5ccc846c"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2e7eb542",
      "metadata": {
        "id": "2e7eb542"
      },
      "outputs": [],
      "source": [
        "# describe X_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c714a85a",
      "metadata": {
        "id": "c714a85a"
      },
      "source": [
        "Using X_train.describe(), identify the two features with max values greater than 100. These features have scales that are quite different than the other features and must be scaled so that they share the same scale as the other features. Standardize one feature and Normalize the other feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "706b99d1",
      "metadata": {
        "id": "706b99d1"
      },
      "outputs": [],
      "source": [
        "# standardize feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3174eccc",
      "metadata": {
        "id": "3174eccc"
      },
      "outputs": [],
      "source": [
        "# normalize feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6e5e7709",
      "metadata": {
        "id": "6e5e7709"
      },
      "outputs": [],
      "source": [
        "# describe X_train again to verify transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2ff24208",
      "metadata": {
        "id": "2ff24208"
      },
      "outputs": [],
      "source": [
        "# X_train.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for and fix outliers\n"
      ],
      "metadata": {
        "id": "oivaPpAeJviD"
      },
      "id": "oivaPpAeJviD",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show correlation heat map for features, check for multicollinearity\n"
      ],
      "metadata": {
        "id": "cnGcuCcDE65x"
      },
      "id": "cnGcuCcDE65x",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://gist.github.com/wjptak/88575bbc5dde446e1186ffd41475c0f1\n",
        "# identify pairs of correlated features\n"
      ],
      "metadata": {
        "id": "112qS2UfIqP8"
      },
      "id": "112qS2UfIqP8",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cee47114",
      "metadata": {
        "id": "cee47114"
      },
      "outputs": [],
      "source": [
        "# delete one of the features out of the pair(s) that show multicollinearity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7f5e001b",
      "metadata": {
        "id": "7f5e001b"
      },
      "outputs": [],
      "source": [
        "# vif test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "21c4564c",
      "metadata": {
        "id": "21c4564c"
      },
      "outputs": [],
      "source": [
        "# verify multicollinearity has been removed by re-showing a correlation heat map for features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering (Category Encoding)"
      ],
      "metadata": {
        "id": "RA4iYsTOSH7Z"
      },
      "id": "RA4iYsTOSH7Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# bi label mapping for features with only two labels\n"
      ],
      "metadata": {
        "id": "v81vS9VrSOk3"
      },
      "id": "v81vS9VrSOk3",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding for features with 3 - 5 labels\n"
      ],
      "metadata": {
        "id": "j_iKM0GfSXjT"
      },
      "id": "j_iKM0GfSXjT",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frequency encoding for features > 5 labels\n"
      ],
      "metadata": {
        "id": "Hej-2BKoSeUI"
      },
      "id": "Hej-2BKoSeUI",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ec3fd3a9",
      "metadata": {
        "id": "ec3fd3a9"
      },
      "outputs": [],
      "source": [
        "# correlation with target (corrwith bar chart)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection"
      ],
      "metadata": {
        "id": "-3IRXJscS5eZ"
      },
      "id": "-3IRXJscS5eZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# output feature selection using variance threshold\n"
      ],
      "metadata": {
        "id": "1auoJUtOS8rS"
      },
      "id": "1auoJUtOS8rS",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output feature selection using select from model"
      ],
      "metadata": {
        "id": "Fne7orPTTEzN"
      },
      "id": "Fne7orPTTEzN",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balanced Dataset?"
      ],
      "metadata": {
        "id": "RQ_kk1ZJTRk4"
      },
      "id": "RQ_kk1ZJTRk4"
    },
    {
      "cell_type": "code",
      "source": [
        "# use a pie chart to check for balance (in y_train)"
      ],
      "metadata": {
        "id": "ag8K_BEXTXlx"
      },
      "id": "ag8K_BEXTXlx",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Models"
      ],
      "metadata": {
        "id": "DD_RSx_9x4Br"
      },
      "id": "DD_RSx_9x4Br"
    },
    {
      "cell_type": "code",
      "source": [
        "# create sklearn logistic regression model and output accuracy, precision, recall, confusion matrix, and classification report\n",
        "# address if dataset is balanced\n"
      ],
      "metadata": {
        "id": "rjmoT2pVx8Tn"
      },
      "id": "rjmoT2pVx8Tn",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Share your thoughts regarding accuracy, precision, recall, confusion matrix, and classification report\n",
        "\n",
        "Type here"
      ],
      "metadata": {
        "id": "ZDYmzs05T5Mw"
      },
      "id": "ZDYmzs05T5Mw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search CV\n",
        "\n",
        "Use the following tunable parameters (hyperparameters) for this section\n",
        "\n",
        "<pre>\n",
        "hyperparameters = {\n",
        "            'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "            'C': np.logspace(-4, 4, 10),\n",
        "            'fit_intercept': [True, False],\n",
        "            'class_weight': ['balanced', 'None'],\n",
        "            'solver': ['lbfgs', 'liblinear']\n",
        "            }\n",
        "</pre>"
      ],
      "metadata": {
        "id": "0iwwXz7ZURTK"
      },
      "id": "0iwwXz7ZURTK"
    },
    {
      "cell_type": "code",
      "source": [
        "# find and output the best parameters for your model using gridsearchcv\n"
      ],
      "metadata": {
        "id": "GXOpeN8QUU4M"
      },
      "id": "GXOpeN8QUU4M",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare the logistic model and the findings from grid search and share your thoughts\n",
        "\n"
      ],
      "metadata": {
        "id": "HHcCZTYqKeOt"
      },
      "id": "HHcCZTYqKeOt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}