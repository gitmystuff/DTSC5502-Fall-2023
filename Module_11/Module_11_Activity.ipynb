{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC5502/blob/main/Module_11/Module_11_Activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp2nv6EmV6He"
      },
      "source": [
        "# Module 11 Activity\n",
        "\n",
        "by Your Name\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "* Colab - get notebook from gitmystuff DTSC5502 repository\n",
        "* Save a Copy in Drive\n",
        "* Remove Copy of\n",
        "* Submit shared link in Canvas\n",
        "\n",
        "## Overview\n",
        "\n",
        "* Decision Tress\n",
        "* Bias Variance Tradeoff\n",
        "* Bootstrapping\n",
        "* Ensemble Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYgKT3cIV6Hj"
      },
      "source": [
        "## Decision Trees\n",
        "\n",
        "* See Decision Trees Notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install ucimlrepo\n"
      ],
      "metadata": {
        "id": "BfIK_p77WsqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqOTRjSwV6Hm"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# iris = fetch_ucirepo(id=53)\n",
        "# X = iris.data.features\n",
        "# y = iris.data.targets\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "#                                                     y['class'],\n",
        "#                                                     test_size=0.20,\n",
        "#                                                     random_state=42)\n",
        "\n",
        "# seaborn pairplot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZcNvAAoV6Hp"
      },
      "outputs": [],
      "source": [
        "# X_train histograms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show probs of y_train\n"
      ],
      "metadata": {
        "id": "9EaZiLr8QR9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intuition for (t, tk)\n"
      ],
      "metadata": {
        "id": "QX8gXq7VRXI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNPIr65YV6Hp"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn import tree\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# print(X_train.head())\n",
        "# print(y_train.value_counts())\n",
        "\n",
        "# model = DecisionTreeClassifier(criterion='gini', random_state=42).fit(X_train, y_train)\n",
        "\n",
        "# plt.figure(figsize=(14, 14))\n",
        "# tree.plot_tree(model,\n",
        "#               feature_names=X_train.columns,\n",
        "#               class_names=['setosa', 'versicolor', 'virginica'],\n",
        "#               filled=False)\n",
        "\n",
        "# plt.tight_layout();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export text\n"
      ],
      "metadata": {
        "id": "KGJSW3qrFpj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split on 2.45\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.scatterplot(x=X_train['petal length'],\n",
        "#                 y=X_train['petal width'],\n",
        "#                 hue=y_train,\n",
        "#                 palette=['red', 'blue', 'green'])\n",
        "\n",
        "# add axvline at 2.45\n",
        "\n",
        "# add axvline at 4.75\n",
        "\n",
        "# add hlines at y=1.75, xmin=2.45, xmax=8,\n",
        "\n"
      ],
      "metadata": {
        "id": "DeJTmlqGP1iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeHCIjuwV6Hr"
      },
      "outputs": [],
      "source": [
        "# further splits\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.scatterplot(x=X_train['petal length'][X_train['petal length']>2.45],\n",
        "#                 y=X_train['petal width'],\n",
        "#                 hue=y_train,\n",
        "#                 palette=['red', 'blue', 'green'])\n",
        "\n",
        "# plt.axhline(y=1.75, color='black')\n",
        "# plt.vlines(x=4.95, ymin=0, ymax=1.75, color='black')\n",
        "# plt.vlines(x=5.45, ymin=0, ymax=1.75, color='black')\n",
        "# plt.axhline(y=1.55, color='black')\n",
        "\n",
        "# plt.xlim(2.45, 8)\n",
        "# plt.ylim(0, )\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJIZ5FS7V6Hs"
      },
      "source": [
        "#### Gini\n",
        "\n",
        "Formula\n",
        "\n",
        "* $1 - \\sum{p_i^2}$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example gini score on petal length\n",
        "# 1 - np.sum(np.square(y_train.value_counts(normalize=True)))"
      ],
      "metadata": {
        "id": "mqFuzxxwBxzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after first split\n",
        "# example = pd.concat([X_train, y_train], axis=1)\n",
        "# print(example.head())\n",
        "# print(example['class'][example['petal length']<2.45].value_counts(normalize=True))\n",
        "# print(example['class'][example['petal length']>=2.45].value_counts(normalize=True))\n",
        "# print(1 - np.sum(np.square(example['class'][example['petal length']>=2.45].value_counts(normalize=True))))"
      ],
      "metadata": {
        "id": "oY2Pdfi9DS2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "AqI87Ip8V6Ht"
      },
      "outputs": [],
      "source": [
        "# show model\n",
        "# model = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42).fit(X_train, y_train)\n",
        "\n",
        "# plt.figure(figsize=(14, 14))\n",
        "# tree.plot_tree(model,\n",
        "#               feature_names=X_train.columns,\n",
        "#               class_names=['setosa', 'versicolor', 'virginica'],\n",
        "#               filled=False)\n",
        "\n",
        "# plt.tight_layout();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk_z5IhQV6Hu"
      },
      "source": [
        "#### Entropy\n",
        "\n",
        "Formula\n",
        "\n",
        "* $-\\sum{p(x)log_2p(x)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezFqQqjbV6Hu"
      },
      "outputs": [],
      "source": [
        "# show model\n",
        "# model = DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=7, random_state=42).fit(X_train, y_train)\n",
        "\n",
        "# plt.figure(figsize=(14, 14))\n",
        "# tree.plot_tree(model,\n",
        "#               feature_names=X_train.columns,\n",
        "#               class_names=['setosa', 'versicolor', 'virginica'],\n",
        "#               filled=False)\n",
        "\n",
        "# plt.tight_layout();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StxQyX_DV6Hu"
      },
      "source": [
        "### Information Gain\n",
        "\n",
        "* See Information Gain Calculation Notebook Local\n",
        "* See Balloons Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bias Variance Tradeoff"
      ],
      "metadata": {
        "id": "4m5LE9RugRkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a title=\"Bigbossfarin, CC0, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Bias_and_variance_contributing_to_total_error.svg\"><img alt=\"Bias and variance contributing to total error\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Bias_and_variance_contributing_to_total_error.svg/640px-Bias_and_variance_contributing_to_total_error.svg.png\"></a>\n",
        "\n",
        "<p>Bigbossfarin, CC0, via Wikimedia Commons</p>"
      ],
      "metadata": {
        "id": "Q_8mTQdfiqYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a title=\"Source: http://scott.fortmann-roe.com/docs/BiasVariance.html\" href=\"https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/images/bias_variance/bullseye.png\"><img width=\"640\" alt=\"Bias and variance contributing to total error\" src=\"https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/images/bias_variance/bullseye.png\"></a>\n",
        "\n",
        "<p>Source: http://scott.fortmann-roe.com/docs/BiasVariance.html</p>"
      ],
      "metadata": {
        "id": "SWX0-M7nM1zZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bootstrapping\n",
        "\n",
        "* See Bootstrapping Notebook\n"
      ],
      "metadata": {
        "id": "qbCvTo_1gVaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Learning"
      ],
      "metadata": {
        "id": "WZyvx0g8emYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bagging\n",
        "\n",
        "* See Ensemble Learning Notebook"
      ],
      "metadata": {
        "id": "Fghe6_dqzqwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boosting\n",
        "\n",
        "* See Boosting Notebook"
      ],
      "metadata": {
        "id": "QWwU0q_TeqDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get dataset\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# cancer = load_breast_cancer()\n",
        "# df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "# df['class'] = cancer.target\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df.drop('class', axis=1), df['class'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "eBXKWv3Oip4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoost"
      ],
      "metadata": {
        "id": "t3ul1ldMi_BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import AdaBoostClassifier\n"
      ],
      "metadata": {
        "id": "Yskkt0j8jHp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting"
      ],
      "metadata": {
        "id": "BQY6uYUOjcN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import GradientBoostingClassifier\n"
      ],
      "metadata": {
        "id": "9GgKYWpOjgxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "KJI_0IU7j57E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from xgboost import XGBClassifier\n",
        "# from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "EqRp9CKsj8oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forests\n",
        "\n",
        "* See Random Forests and Grid Search Notebook\n",
        "* See Penguins Notebook"
      ],
      "metadata": {
        "id": "AH2OHelDzu3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the penguins dataset; species = y; explore the dataset\n",
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# df = sns.load_dataset('penguins')\n",
        "# df.dropna(how='any', inplace=True)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df.drop('species', axis=1), df['species'], test_size=0.25, random_state=42)\n",
        "\n",
        "# X_train['sex'] = X_train['sex'].map({'Female':1,'Male':0})\n",
        "# X_test['sex'] = X_test['sex'].map({'Female':1,'Male':0})\n",
        "\n",
        "# ohe = OneHotEncoder(categories='auto', drop='first', sparse_output=False)\n",
        "\n",
        "# ohe_train = ohe.fit_transform(X_train[['island']])\n",
        "# ohe_train = pd.DataFrame(ohe_train, columns=ohe.get_feature_names_out(['island']))\n",
        "# ohe_train.index = X_train.index\n",
        "# X_train = X_train.join(ohe_train)\n",
        "# X_train.drop(['island'], axis=1, inplace=True)\n",
        "\n",
        "# ohe_test = ohe.transform(X_test[['island']])\n",
        "# ohe_test = pd.DataFrame(ohe_test, columns=ohe.get_feature_names_out(['island']))\n",
        "# ohe_test.index = X_test.index\n",
        "# X_test = X_test.join(ohe_test)\n",
        "# X_test.drop(['island'], axis=1, inplace=True)\n",
        "\n",
        "# y_train.value_counts()\n",
        "# y_train = y_train.map({'Adelie':0,'Gentoo':1, 'Chinstrap':2})\n",
        "# y_test = y_test.map({'Adelie':0,'Gentoo':1, 'Chinstrap':2})\n",
        "\n",
        "# X_train.head()"
      ],
      "metadata": {
        "id": "Tk-vw3v2k5rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model and gridsearch\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.model_selection import GridSearchCV\n"
      ],
      "metadata": {
        "id": "51O3pI3Mk70_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final RandomForestClassifier model here using set_params and best_params; provide an accuracy score\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "KxTm5Idzli6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection\n",
        "\n",
        "* Random Forest Importance: selects features with values are greater than the mean of all the coefficients\n",
        "* Recursive Feature Selection: removes the weakest feature per iteration and then rebuilds random forest and repeats till criterion is met"
      ],
      "metadata": {
        "id": "QW-TfObVzbAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "# import pandas as pd\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# iris = load_iris()\n",
        "# X = iris.data\n",
        "# y = iris.target\n",
        "\n",
        "# df = pd.DataFrame(data=X, columns=iris.feature_names)\n",
        "# df['species'] = y\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df.drop('species', axis=1),\n",
        "#                                                     df['species'],\n",
        "#                                                     test_size=0.25,\n",
        "#                                                     random_state=42)"
      ],
      "metadata": {
        "id": "wa3mzQTi1fc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest importance\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# selects = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "# selects.fit(X_train, y_train)\n",
        "# selected_feats = X_train.columns[(selects.get_support())]\n",
        "# selected_feats"
      ],
      "metadata": {
        "id": "rVrSvQIs0u77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recursive feature selection\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.feature_selection import RFE\n",
        "\n",
        "# selects = RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=3)\n",
        "# selects.fit(X_train, y_train)\n",
        "# selected_feats = X_train.columns[(selects.get_support())]\n",
        "# print(selected_feats)\n",
        "# print(selects.estimator_.feature_importances_)\n",
        "# [feat for feat in zip(selected_feats, selects.estimator_.feature_importances_)]"
      ],
      "metadata": {
        "id": "3AmGUYfl02Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recursive feature selection cv\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.feature_selection import RFECV\n",
        "\n",
        "# selects = RFECV(RandomForestClassifier(n_estimators=100, random_state=42), step=1, cv=5)\n",
        "# selects.fit(X_train, y_train)\n",
        "# selected_feats = X_train.columns[(selects.get_support())]\n",
        "# print(selected_feats)\n",
        "# print(selects.estimator_.feature_importances_)\n",
        "# [feat for feat in zip(selected_feats, selects.estimator_.feature_importances_)]"
      ],
      "metadata": {
        "id": "jAvbvdur1GMA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}