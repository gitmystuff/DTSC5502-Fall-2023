{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC5502/blob/main/Module_08/Module_8_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfa4ccd",
      "metadata": {
        "id": "5cfa4ccd"
      },
      "source": [
        "# Module 8 Assignment\n",
        "\n",
        "by Your Name\n",
        "\n",
        "## Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be sure to replace the stud_id variable with you student id. Automatic 0 if not properly replaced."
      ],
      "metadata": {
        "id": "T_NyOA_WUhEC"
      },
      "id": "T_NyOA_WUhEC"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0d58ad25",
      "metadata": {
        "id": "0d58ad25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2488e0e-7f17-4d5a-ca08-c438be2a7c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['qozv', 'vkyr', 'kjko', 'fpap', 'aqti', 'rpqc', 'irba', 'qoan', 'lkty', 'ggsf', 'hris', 'tend', 'sxov', 'lnfq', 'doyy', 'kxvy', 'mlop', 'jntc', 'uxln', 'rvvh', 'dpfo', 'ihgw', 'fhqr', 'mmvg', 'idpf', 'nbtd', 'uwkt', 'sror', 'vfcu', 'gbkp']\n"
          ]
        }
      ],
      "source": [
        "# create seed, run this cell as is, only edit your stud_id\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "n = 500\n",
        "\n",
        "def make_null(r, w):\n",
        "    # rtn = random.choices([np.nan, r])\n",
        "    wi = w * .1\n",
        "    rtn = np.random.choice([r, np.NaN], p=[1-wi, wi])\n",
        "    return re.sub(r\"[\\[\\]]\",'', str(rtn))\n",
        "\n",
        "\n",
        "# provide your student id as stud_id, replace 123456789 (automatice 0 if not replaced with your student id)\n",
        "stud_id = 123456789\n",
        "my_seed = random.seed(stud_id)\n",
        "\n",
        "# Do not edit this cell beyond this line\n",
        "variables = [''.join(random.choices(string.ascii_lowercase, k=4)) for _ in range(30)]\n",
        "print(variables)\n",
        "\n",
        "X, y = make_regression(n_samples=n, n_features=20, n_informative=12)\n",
        "# random.shuffle(variables)\n",
        "cols = variables[:20]\n",
        "df = pd.DataFrame(data=X, columns=cols)\n",
        "df[cols[0]] = round(df[cols[0]], 4)\n",
        "df[variables[20]] = 0.03\n",
        "df[variables[21]] = 0.07\n",
        "df[variables[22]] = df[variables[0]]\n",
        "df[variables[23]] = df[cols[1]]\n",
        "df[variables[24]] = df[variables[20]].apply(make_null, args=(1,))\n",
        "df[variables[25]] = df[variables[13]].apply(make_null, args=(1,))\n",
        "df[variables[26]] = random.sample(range(100, 1000), k=n)\n",
        "df[variables[27]] = random.sample(range(1000, 10000), k=n)\n",
        "df[variables[28]] = np.random.choice([.4, .1], p=[.98, .02])\n",
        "\n",
        "df[variables[7]] = df[variables[7]].apply(lambda r: abs(r) if (r < -0.03) else r)\n",
        "df[variables[8]] = df[variables[8]].apply(lambda r: abs(r)*-1 if (r > 0.02) else r)\n",
        "df[variables[9]] = df[variables[9]].apply(lambda r: abs(r) if (r < -0.01) else r)\n",
        "df[variables[7]] = df[variables[7]].apply(make_null, args=(1,))\n",
        "df[variables[8]] = df[variables[8]].apply(make_null, args=(1,))\n",
        "df[variables[9]] = df[variables[9]].apply(make_null, args=(1,))\n",
        "df[variables[17]] = df[variables[17]].apply(make_null, args=(1,))\n",
        "df[variables[18]] = df[variables[18]].apply(make_null, args=(1,))\n",
        "df[variables[19]] = df[variables[19]].apply(make_null, args=(1,))\n",
        "\n",
        "df = df[np.random.default_rng(seed=my_seed).permutation(df.columns.values)]\n",
        "\n",
        "df = df.assign(survival=[random.choice(['x', 'o']) for i in range(n)])\n",
        "df = df.assign(treatment=[random.choice(['yes', 'no']) for i in range(n)])\n",
        "df = df.assign(level=[random.choice(['level 1', 'level 2', 'level 3']) for i in range(n)])\n",
        "df = df.assign(stage=[random.choice(['stage 5', 'stage 4', 'stage 3', 'stage 2', 'stage 1']) for i in range(n)])\n",
        "\n",
        "df['target'] = y\n",
        "\n",
        "dupes = df.loc[0:10]\n",
        "df = pd.concat([df, dupes], axis=0)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df.to_csv('Assignment 8.csv', index=False) # comment this out after successful run so that you don't overwrite your data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the dataset created above into a datagrame and output shape, info, and head\n"
      ],
      "metadata": {
        "id": "95TydT6It1YS"
      },
      "id": "95TydT6It1YS",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a8bdc28",
      "metadata": {
        "id": "5a8bdc28"
      },
      "outputs": [],
      "source": [
        "# output and drop constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c1f6efe4",
      "metadata": {
        "id": "c1f6efe4"
      },
      "outputs": [],
      "source": [
        "# output quasi constants and drop quasi constants (don't drop bi-label features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f65de913",
      "metadata": {
        "id": "f65de913"
      },
      "outputs": [],
      "source": [
        "# output and drop duplicate rows, print shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f0276f85",
      "metadata": {
        "id": "f0276f85"
      },
      "outputs": [],
      "source": [
        "# check of duplicate columns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicate features and output shape\n"
      ],
      "metadata": {
        "id": "3nuDA3WyL2b1"
      },
      "id": "3nuDA3WyL2b1",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1c2b124f",
      "metadata": {
        "id": "1c2b124f"
      },
      "source": [
        "### Imputation\n",
        "\n",
        "Use histograms to view the shape of your numerical features.\n",
        "* Use median to replace missing data for skewed features\n",
        "* Use interpolation to replace missing data for features that look normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ad3159bc",
      "metadata": {
        "id": "ad3159bc"
      },
      "outputs": [],
      "source": [
        "# plot histograms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show null values for each variable\n"
      ],
      "metadata": {
        "id": "nbAh7UBkHSvc"
      },
      "id": "nbAh7UBkHSvc",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print info to recall which variables are numeric vs categorical\n"
      ],
      "metadata": {
        "id": "PoJs2L-0MHQt"
      },
      "id": "PoJs2L-0MHQt",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a5b1afe7",
      "metadata": {
        "id": "a5b1afe7"
      },
      "outputs": [],
      "source": [
        "# replace missing data with appropriate mean, median, or mode and confirm with isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "e8HY-whQxJ7n"
      },
      "id": "e8HY-whQxJ7n"
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split (target is the dependent (y) variable), print the shapes for X_train and X_test\n"
      ],
      "metadata": {
        "id": "hRgrnMZFxb6K"
      },
      "id": "hRgrnMZFxb6K",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important:** We will not be using df (the dataframe we created above) for the remaining code. Instead we will be using X_train for df and X_test when appropriate."
      ],
      "metadata": {
        "id": "vdjLRyFbH_Cp"
      },
      "id": "vdjLRyFbH_Cp"
    },
    {
      "cell_type": "markdown",
      "id": "5ccc846c",
      "metadata": {
        "id": "5ccc846c"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2e7eb542",
      "metadata": {
        "id": "2e7eb542"
      },
      "outputs": [],
      "source": [
        "# describe X_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c714a85a",
      "metadata": {
        "id": "c714a85a"
      },
      "source": [
        "Using X_train.describe(), identify the two features with max values greater than 100. These features have scales that are quite different than the other features and must be scaled so that they share the same scale as the other features. Standardize one feature and Normalize the other feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "706b99d1",
      "metadata": {
        "id": "706b99d1"
      },
      "outputs": [],
      "source": [
        "# standardize feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3174eccc",
      "metadata": {
        "id": "3174eccc"
      },
      "outputs": [],
      "source": [
        "# normalize feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6e5e7709",
      "metadata": {
        "id": "6e5e7709"
      },
      "outputs": [],
      "source": [
        "# describe X_train again to verify transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2ff24208",
      "metadata": {
        "id": "2ff24208"
      },
      "outputs": [],
      "source": [
        "# X_train.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for and fix outliers\n"
      ],
      "metadata": {
        "id": "oivaPpAeJviD"
      },
      "id": "oivaPpAeJviD",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show correlation heat map for features, check for multicollinearity\n"
      ],
      "metadata": {
        "id": "cnGcuCcDE65x"
      },
      "id": "cnGcuCcDE65x",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://gist.github.com/wjptak/88575bbc5dde446e1186ffd41475c0f1\n",
        "# identify pairs of correlated features\n"
      ],
      "metadata": {
        "id": "112qS2UfIqP8"
      },
      "id": "112qS2UfIqP8",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cee47114",
      "metadata": {
        "id": "cee47114"
      },
      "outputs": [],
      "source": [
        "# delete one of the features out of the pair(s) that show multicollinearity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7f5e001b",
      "metadata": {
        "id": "7f5e001b"
      },
      "outputs": [],
      "source": [
        "# vif test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "21c4564c",
      "metadata": {
        "id": "21c4564c"
      },
      "outputs": [],
      "source": [
        "# verify multicollinearity has been removed by re-showing a correlation heat map for features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ec3fd3a9",
      "metadata": {
        "id": "ec3fd3a9"
      },
      "outputs": [],
      "source": [
        "# correlation with target (corrwith bar chart)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Models"
      ],
      "metadata": {
        "id": "DD_RSx_9x4Br"
      },
      "id": "DD_RSx_9x4Br"
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn linear regression with mse and R-squared\n"
      ],
      "metadata": {
        "id": "rjmoT2pVx8Tn"
      },
      "id": "rjmoT2pVx8Tn",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# statsmodel ols with summary\n"
      ],
      "metadata": {
        "id": "0m6jK4UOx-83"
      },
      "id": "0m6jK4UOx-83",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the coefficient using linear algebra matrices\n"
      ],
      "metadata": {
        "id": "T-vE3Bc1yBTe"
      },
      "id": "T-vE3Bc1yBTe",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lasso / l1 Regularization\n",
        "\n",
        "* $\\alpha = \\sum|w_i|$\n",
        "* Forces weak features to have zero coefficients\n",
        "* Performs feature selection\n",
        "* Models can be unstable (coefficients fluctuate significantly on data changes with correlated features)"
      ],
      "metadata": {
        "id": "M3jJhzlrol9m"
      },
      "id": "M3jJhzlrol9m"
    },
    {
      "cell_type": "code",
      "source": [
        "# lasso regularization\n",
        "\n"
      ],
      "metadata": {
        "id": "1Ffh84wgoqdG"
      },
      "id": "1Ffh84wgoqdG",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ridge / l2 Regularization\n",
        "\n",
        "* $\\alpha = \\sum w_i^2$\n",
        "* Spreads out coefficients more equally\n",
        "* Exposes correlated features (have similar coefficients)\n",
        "* Models are more stable (coefficients don't fluctuate as much on data changes with correlated features)"
      ],
      "metadata": {
        "id": "96eWYdl5pLKW"
      },
      "id": "96eWYdl5pLKW"
    },
    {
      "cell_type": "code",
      "source": [
        "# ridge regularization\n"
      ],
      "metadata": {
        "id": "w8zVEl1EpPA5"
      },
      "id": "w8zVEl1EpPA5",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the coefficients from the linear regression, lasso, and ridge models\n"
      ],
      "metadata": {
        "id": "74ZVO5Odp4XT"
      },
      "id": "74ZVO5Odp4XT",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_reg correlation with target\n"
      ],
      "metadata": {
        "id": "VQGli16w2FmJ"
      },
      "id": "VQGli16w2FmJ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ols summary recall\n"
      ],
      "metadata": {
        "id": "xtdfkpVd6pvU"
      },
      "id": "xtdfkpVd6pvU",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a statsmodel ols model using the relevant features found in the Lasso model, print the summary\n"
      ],
      "metadata": {
        "id": "yUJFlw4z6uu4"
      },
      "id": "yUJFlw4z6uu4",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Comparison\n",
        "\n",
        "Provide a comparison between the original OLS model and the reduced features OLS model created with the help of l1 regularization. Make mention of the following:\n",
        "\n",
        "* R-squared\n",
        "* Adj R-squared\n",
        "* F-statistic\n",
        "* AIC and BIC\n",
        "* The coefficients that are common in both models\n",
        "* The standard error for each coefficient\n",
        "* The t-statistic\n",
        "* The critical value\n",
        "* The p-value\n",
        "* The 95% confidence interval"
      ],
      "metadata": {
        "id": "tImdeyQMFjFi"
      },
      "id": "tImdeyQMFjFi"
    },
    {
      "cell_type": "code",
      "source": [
        "# create, train, and test a model using a pipeline that includes a StandardScaler and a Lasso Regression model, output the training and testing scores\n"
      ],
      "metadata": {
        "id": "W-k47h6xBgIq"
      },
      "id": "W-k47h6xBgIq",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment Summary\n",
        "\n"
      ],
      "metadata": {
        "id": "HHcCZTYqKeOt"
      },
      "id": "HHcCZTYqKeOt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}