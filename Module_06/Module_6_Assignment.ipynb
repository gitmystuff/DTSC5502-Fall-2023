{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC5502/blob/main/Module_06/Module_6_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfa4ccd",
      "metadata": {
        "id": "5cfa4ccd"
      },
      "source": [
        "# Module 6 Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3063e49f",
      "metadata": {
        "id": "3063e49f"
      },
      "source": [
        "You've been asked to clean and explore a dataset containing employee ratings  for months of review cycles.\n",
        "\n",
        "Enter your student id, in the next cell, when asked and then run the next two cells. The second cell will create the dataset you will be working on. If you run the second cell again, it will generate a new dataset so be aware."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4793462",
      "metadata": {
        "id": "d4793462"
      },
      "source": [
        "### Generate Seed and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0d58ad25",
      "metadata": {
        "id": "0d58ad25"
      },
      "outputs": [],
      "source": [
        "# create seed, run this cell as is, do not edit\n",
        "import random\n",
        "\n",
        "# provide your student id as stud_id, replace 123456789 (automatice 0 if not replaced with your student id)\n",
        "stud_id = 123456789\n",
        "my_seed = random.seed(stud_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "617bce76",
      "metadata": {
        "id": "617bce76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d25153a-d3f5-4ffc-dfd0-7f21fe6b8f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pitt Topsy', 'Nairobi Keyes', 'Riemannian Nairobi', 'Thailand Malthus', 'Nate Pierre', 'Trumbull Furman', 'Anglican Indira', 'Esther Antares', 'Danbury Kurd', 'Rena Kevin', 'Burke Jensen', 'Kresge Merritt', 'Baffin Alistair', 'Carrara Normandy', 'Viet Bigelow', 'Andrew Stewart', 'Kilimanjaro Polaroid', 'Naomi Champaign', 'Polaris Alphonse', 'Holst Khrushchev']\n",
            "['Nate Pierre', 'Naomi Champaign', 'Rena Kevin', 'Anglican Indira', 'Pitt Topsy', 'Viet Bigelow', 'Carrara Normandy', 'Andrew Stewart', 'Kilimanjaro Polaroid', 'Baffin Alistair']\n"
          ]
        }
      ],
      "source": [
        "# run this cell as is, do not edit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import urllib.request\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "\n",
        "def make_null(r, w):\n",
        "    rtn = random.choices([np.nan, r], weights=[w, 100-w])\n",
        "    return re.sub(r\"[\\[\\]]\",'', str(rtn))\n",
        "\n",
        "words = []\n",
        "\n",
        "# \"https://svnweb.freebsd.org/csrg/share/dict/words?view=co&content-type=text/plain\"\n",
        "url = 'https://raw.githubusercontent.com/gitmystuff/Datasets/main/words.txt'\n",
        "\n",
        "for word in urllib.request.urlopen(url):\n",
        "    words.append(word.decode('utf-8').replace('\\n', ''))\n",
        "\n",
        "capitalized = [word for word in words if word[0].isupper()]\n",
        "proper_names  = [word for word in capitalized if not word.isupper()]\n",
        "\n",
        "variables = []\n",
        "for n in range(20):\n",
        "    variables.append(' '.join([proper_names[random.randint(0, len(proper_names))] for i in range(2)]))\n",
        "\n",
        "print(variables)\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=10, n_informative=6)\n",
        "random.shuffle(variables)\n",
        "cols = variables[:10]\n",
        "print(cols)\n",
        "df = pd.DataFrame(data=X, columns=cols)\n",
        "df[cols[0]] = round(df[cols[0]], 4)\n",
        "df[variables[10]] = 0.03\n",
        "df[variables[11]] = 0.07\n",
        "df[variables[12]] = df[variables[0]]\n",
        "df[variables[13]] = df[cols[1]]\n",
        "df[variables[10]] = df[variables[10]].apply(make_null, args=(2,))\n",
        "df[variables[13]] = df[variables[13]].apply(make_null, args=(5,))\n",
        "df[variables[14]] = random.sample(range(100, 1000), k=100)\n",
        "df[variables[15]] = random.sample(range(1000, 10000), k=100)\n",
        "\n",
        "df[variables[7]] = df[variables[7]].apply(lambda r: abs(r) if (r < -0.02) else r)\n",
        "df[variables[8]] = df[variables[8]].apply(lambda r: abs(r)*-1 if (r > 0.01) else r)\n",
        "df[variables[9]] = df[variables[9]].apply(lambda r: abs(r) if (r < -0.01) else r)\n",
        "df[variables[7]] = df[variables[7]].apply(make_null, args=(7,))\n",
        "df[variables[8]] = df[variables[8]].apply(make_null, args=(8,))\n",
        "df[variables[9]] = df[variables[9]].apply(make_null, args=(9,))\n",
        "\n",
        "df = df[np.random.default_rng(seed=my_seed).permutation(df.columns.values)]\n",
        "\n",
        "cats = [random.choice(['blue', 'white']) for i in range(100)]\n",
        "df['Collar'] = cats\n",
        "cats = [random.choice(['opt in', 'opt out']) for i in range(100)]\n",
        "df['401K'] = cats\n",
        "cats = [random.choice(['medical plan 1', 'medical plan 2', 'medical plan 3']) for i in range(100)]\n",
        "df['Medical'] = cats\n",
        "cats = [random.choice(['5 stars', '4 stars', '3 stars', '2 stars', '1 star']) for i in range(100)]\n",
        "df['Stars'] = cats\n",
        "\n",
        "df['Total Sales'] = y\n",
        "\n",
        "dupes = df.loc[0:5]\n",
        "df = pd.concat([df, dupes], axis=0)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df.to_csv('Assgn 6.csv', index=False) # comment this out after successful run so that you don't overwrite your data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a290e0a9",
      "metadata": {
        "id": "a290e0a9"
      },
      "source": [
        "### Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "806b9dca",
      "metadata": {
        "id": "806b9dca"
      },
      "outputs": [],
      "source": [
        "# create dataframe from Assgn 6.csv and print shape, info(), and head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5a8bdc28",
      "metadata": {
        "id": "5a8bdc28"
      },
      "outputs": [],
      "source": [
        "# identify constants\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop constants\n"
      ],
      "metadata": {
        "id": "vlt3ZpIiD9XI"
      },
      "id": "vlt3ZpIiD9XI",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c1f6efe4",
      "metadata": {
        "id": "c1f6efe4"
      },
      "outputs": [],
      "source": [
        "# identify quasi constant values (sometimes these may be boolean features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "93d98949",
      "metadata": {
        "id": "93d98949"
      },
      "outputs": [],
      "source": [
        "# drop the variables with low cardinality (quasi constants with unbalanced labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f65de913",
      "metadata": {
        "id": "f65de913"
      },
      "outputs": [],
      "source": [
        "# identify duplicate rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6ac5c315",
      "metadata": {
        "id": "6ac5c315"
      },
      "outputs": [],
      "source": [
        "# drop duplicate rows and print shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f0276f85",
      "metadata": {
        "id": "f0276f85"
      },
      "outputs": [],
      "source": [
        "# check of duplicate columns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicate features\n"
      ],
      "metadata": {
        "id": "3nuDA3WyL2b1"
      },
      "id": "3nuDA3WyL2b1",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1c2b124f",
      "metadata": {
        "id": "1c2b124f"
      },
      "source": [
        "### Imputation\n",
        "\n",
        "Use histograms to view the shape of your numerical features.\n",
        "* Use median to replace missing data for skewed features\n",
        "* Use interpolation to replace missing data for features that look normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ad3159bc",
      "metadata": {
        "id": "ad3159bc"
      },
      "outputs": [],
      "source": [
        "# plot histograms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show null values for each variable\n"
      ],
      "metadata": {
        "id": "nbAh7UBkHSvc"
      },
      "id": "nbAh7UBkHSvc",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print info to recall which variables are numeric vs categorical\n"
      ],
      "metadata": {
        "id": "PoJs2L-0MHQt"
      },
      "id": "PoJs2L-0MHQt",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a5b1afe7",
      "metadata": {
        "id": "a5b1afe7"
      },
      "outputs": [],
      "source": [
        "# replace missing data with appropriate mean, median, or mode and confirm with isnull().sum()\n",
        "# https://pythonnumericalmethods.berkeley.edu/notebooks/chapter17.01-Interpolation-Problem-Statement.html\n",
        "# https://www.analyticsvidhya.com/blog/2021/06/power-of-interpolation-in-python-to-fill-missing-values/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split\n",
        "\n",
        "Whatever we do with X_train we have to do with X_test but with some considerations:\n",
        "\n",
        "* if we scale a feature, we fit_transform (train) on X_train and then only transform on X_test\n",
        "* For things like Variance Inflation Factor, we find the VIF scores for X_train only, but after we decide which features to drop we have to drop from both X_train and X_test"
      ],
      "metadata": {
        "id": "imF5Wry4Fk-U"
      },
      "id": "imF5Wry4Fk-U"
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split (Total Sales is the dependent (y) variable), print the shapes for X_train and X_test\n"
      ],
      "metadata": {
        "id": "CZmM1sgVFoN9"
      },
      "id": "CZmM1sgVFoN9",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important:** We will not be using df (the dataframe we created above) for the remaining code. Instead we will be using X_train for df and X_test when appropriate."
      ],
      "metadata": {
        "id": "vdjLRyFbH_Cp"
      },
      "id": "vdjLRyFbH_Cp"
    },
    {
      "cell_type": "markdown",
      "id": "5ccc846c",
      "metadata": {
        "id": "5ccc846c"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2e7eb542",
      "metadata": {
        "id": "2e7eb542"
      },
      "outputs": [],
      "source": [
        "# describe df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c714a85a",
      "metadata": {
        "id": "c714a85a"
      },
      "source": [
        "Using X_train.describe(), identify the two features with max values greater than 100. These features have scales that are quite different than the other features and must be scaled so that they share the same scale as the other features. Standardize one feature and Normalize the other feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "706b99d1",
      "metadata": {
        "id": "706b99d1"
      },
      "outputs": [],
      "source": [
        "# standardize feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3174eccc",
      "metadata": {
        "id": "3174eccc"
      },
      "outputs": [],
      "source": [
        "# normalize feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6e5e7709",
      "metadata": {
        "id": "6e5e7709"
      },
      "outputs": [],
      "source": [
        "# describe data again to verify transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2ff24208",
      "metadata": {
        "id": "2ff24208"
      },
      "outputs": [],
      "source": [
        "# df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for outliers\n"
      ],
      "metadata": {
        "id": "oivaPpAeJviD"
      },
      "id": "oivaPpAeJviD",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7f5e001b",
      "metadata": {
        "id": "7f5e001b"
      },
      "outputs": [],
      "source": [
        "# vif test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cee47114",
      "metadata": {
        "id": "cee47114"
      },
      "outputs": [],
      "source": [
        "# delete one of the features out of the pair(s) that show multicollinearity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "709a87a6",
      "metadata": {
        "id": "709a87a6"
      },
      "outputs": [],
      "source": [
        "# verify you no longer have multicollinearity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "21c4564c",
      "metadata": {
        "id": "21c4564c"
      },
      "outputs": [],
      "source": [
        "# show correlation heat map for features, check for multicollinearity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ec3fd3a9",
      "metadata": {
        "id": "ec3fd3a9"
      },
      "outputs": [],
      "source": [
        "# correlation with target\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create and train a Linear Regression model from the sklearn.linear_model library (be sure to only use numeric data - _get_numeric_data() for X_train and X_test)\n",
        "# make predictions and provide MSE and RSquared scores\n"
      ],
      "metadata": {
        "id": "GUEymnm-I1mR"
      },
      "id": "GUEymnm-I1mR",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an OLS model from statsmodels and print the summary\n"
      ],
      "metadata": {
        "id": "fUKaDG5OKETg"
      },
      "id": "fUKaDG5OKETg",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seaborn pairplot showing the scatter plots of three features with the lowest p-values from the summary above\n",
        "# include line of best fit and the translucent confidence intervals\n"
      ],
      "metadata": {
        "id": "IxYegd57Kc6B"
      },
      "id": "IxYegd57Kc6B",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "Share some thoughts on what you have discovered during this analysis"
      ],
      "metadata": {
        "id": "HHcCZTYqKeOt"
      },
      "id": "HHcCZTYqKeOt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}